@book{Liu2012,
abstract = {Mining introduces a novel feature selection technique that establishes a general platform for studying existing feature selection algorithms and developing new algorithms for emerging problems in real-world applications. This technique represents a unified framework for supervised, unsupervised, and semisupervised feature selections. The book explores the latest research achievements, sheds light on new research directions, and stimulates readers to make the next creative breakthroughs. It presents the intrinsic ideas behind spectral feature selection, its theoretical foundations, its connections to other algorithms, and its use in handling both large-scale data sets and small sample problems. The authors also cover feature selection and feature extraction, including basic concepts, popular existing algorithms, and applications. A timely introduction to spectral feature selection, this book illustrates the potential of this powerful dimensionality reduction technique in high-dimensional data processing. Readers learn how to use spectral feature selection to solve challenging problems in real-life applications and discover how general feature selection and extraction are connected to spectral feature selection.},
author = {Liu, Zhao and Zhao, Zheng Alan and Liu, Huan},
file = {:home/lk/Documents/Books/MachineLearning/FeatureSelection/Spectral feature selection for data mining.pdf:pdf},
isbn = {9781439862100},
title = {{Spectral Feature Selection for Data Mining Spectral Feature Selection for Data Chapman & Hall/CRC Data Mining and Knowledge Discovery Series Chapman & Hall/CRC Data Mining and Knowledge Discovery Series Spectral Feature Selection for Data Mining Spectral}},
year = {2012}
}
@book{Bolon-Canedo2018,
abstract = {This book offers a comprehensive overview of ensemble learning in the field of feature selection (FS), which consists of combining the output of multiple methods to obtain better results than any single method. It reviews various techniques for combining partial results, measuring diversity and evaluating ensemble performance. With the advent of Big Data, feature selection (FS) has become more necessary than ever to achieve dimensionality reduction. With so many methods available, it is difficult to choose the most appropriate one for a given setting, thus making the ensemble paradigm an interesting alternative. The authors first focus on the foundations of ensemble learning and classical approaches, before diving into the specific aspects of ensembles for FS, such as combining partial results, measuring diversity and evaluating ensemble performance. Lastly, the book shows examples of successful applications of ensembles for FS and introduces the new challenges that researchers now face. As such, the book offers a valuable guide for all practitioners, researchers and graduate students in the areas of machine learning and data mining.},
author = {Bol{\'{o}}n-Canedo, Ver{\'{o}}nica and Alonso-Betanzos, Amparo},
booktitle = {Intelligent Systems Reference Library Book},
file = {:home/lk/Documents/Books/MachineLearning/FeatureSelection/Recent Advances in Ensembles for Feature Selection.pdf:pdf},
isbn = {9783319900797},
pages = {1--205},
title = {{Recent Advances in Ensembles for Feature Selection}},
url = {http://link.springer.com/10.1007/978-3-319-90080-3},
volume = {147},
year = {2018}
}
@book{Tari,
author = {Tari, Zahir and Fahad, Adil and Almalawi, Abdulmohsen and Yi, Xun},
file = {:home/lk/Documents/Books/MachineLearning/FeatureSelection/Network Classification for Traffic Management.pdf:pdf},
isbn = {9781785619212},
title = {{Network Classification for Traffic Management}}
}
@book{Masters2020,
author = {Masters, Timothy},
booktitle = {Modern Data Mining Algorithms in C++ and CUDA C},
doi = {10.1007/978-1-4842-5988-7},
file = {:home/lk/Documents/Books/MachineLearning/FeatureSelection/Modern Data Mining Algorithms in C++ and CUDA C.pdf:pdf},
isbn = {9781484259870},
title = {{Modern Data Mining Algorithms in C++ and CUDA C}},
year = {2020}
}
@misc{Fontaine2018,
author = {Fontaine, Alan},
file = {:home/lk/Documents/Books/MachineLearning/FeatureSelection/Mastering Predictive Analytics with scikit-learn and TensorFlow.epub:epub},
title = {{Mastering Predictive Analytics with scikit-learn and TensorFlow}},
year = {2018}
}
@book{,
file = {:home/lk/Documents/Books/MachineLearning/FeatureSelection/Feature Selection for Knowledge Discovery and Data Mining.pdf:pdf},
isbn = {9781461556893},
title = {{Feature Selection for Knowledge Discovery and}}
}
@book{Bolon-Canedo2016,
abstract = {Abstract Feature selection has been a fruitful field of research and it is undoubtedly important. However, a statement like “the best feature selection method” simply does not exist in general, making it difficult for users to select one method over another. For this reason, the objective of this chapter is to perform a critical review of state-of-the-art feature selection methods. The chapter starts with the description of the existing reviews (Section 3.1). Then, Section 3.2 depicts the methods and data involved in the experiments of this chapter and Section 3.3 shows the results obtained. In Section 3.4 we present several cases of study, aiming at deciding between methods that showed similar behaviors. Finally, Section 3.5 analyzes and discusses the findings of the experimental study and Section 3.6 summarizes this chapter.},
author = {Bol{\'{o}}n-Canedo, Ver{\'{o}}nica and S{\'{a}}nchez-Maro{\~{n}}o, Noelia and Alonso-Betanzos, Amparo},
file = {:home/lk/Documents/Books/MachineLearning/FeatureSelection/Feature Selection for High-Dimensional Data.pdf:pdf},
isbn = {9783319218571},
pages = {1--10},
title = {{Artificial Intelligence: Foundations, Theory, and Algorithms Feature Selection for High-Dimensional Data - Chapter 3: A Critical Review of Feature Selection Methods}},
url = {www.springer.com/series/},
year = {2016}
}
@book{Stanczyk2015,
abstract = {Surrounded by data and information in various forms we need to characterise and describe objects of our universe using some attributes of nominal or numerical type. Selection of features can be performed basing on domain knowledge, executed through dedicated approaches, driven by some particular inherent properties ofmethodologies and techniques employed, or governed by other factors or rules. This chapter presents a general and brief introduction to topics of feature selection for data and pattern recognition. Its main aim is to provide short descriptions of the chapters included in this volume.},
author = {Sta{\'{n}}czyk, Urszula and Jain, Lakhmi C.},
booktitle = {Studies in Computational Intelligence},
doi = {10.1007/978-3-662-45620-0_1},
file = {:home/lk/Documents/Books/MachineLearning/FeatureSelection/Feature selection for data and pattern recognition.pdf:pdf},
isbn = {9783662456194},
issn = {1860949X},
keywords = {Data mining,Feature,Feature selection,Pattern recognition},
pages = {1--7},
title = {{Feature selection for data and pattern recognition: An introduction}},
volume = {584},
year = {2015}
}
@book{Kacprzyk2006,
author = {Kacprzyk, Janusz},
booktitle = {James J. Buckley Fuzzy Probability and Statistics Hung T. Nguyen Andreas N{\"{u}}rnberger Fuzzy Control Cengiz Kahraman Fuzzy Applications in Industrial Engineering Zongmin Ma Chaos},
file = {:home/lk/Documents/Books/MachineLearning/FeatureSelection/Feature Extraction.pdf:pdf},
isbn = {9783540354871},
number = {207},
pages = {3--540},
title = {{Studies in Fuzziness and Soft Computing, Volume 207 Editor-in-chief}},
url = {http://scholar.google.com/scholar?hl=en%7B&%7DbtnG=Search%7B&%7Dq=intitle:Feature+Extraction+Foundations+and+Applications%7B#%7D1$%5C$nhttp://link.springer.com/content/pdf/10.1007/978-3-540-35488-8.pdf},
volume = {191},
year = {2006}
}
@misc{,
abstract = {Choosing the best method for feature selection depends on the extent of a-priori knowledge of the problem. We present two basic approaches. One involves computationally effective floating-search methods; the other trades off the requirement for a-priori information for the requirement of sufficient data to represent the distributions involved. We've developed methods for statistical pattern recognition that, based on the user's level of knowledge of a problem, can reduce the problem's dimensionality. We believe that these methods can enrich the methodology of subset selection for other fields of AI. This article provides an overview of our methods and techniques. focusing on the basic principles and their potential use},
booktitle = {Feature Extraction, Construction and Selection},
doi = {10.1007/978-1-4615-5725-8},
file = {:home/lk/Documents/Books/MachineLearning/FeatureSelection/Feature Extraction, Construction and Selection.djvu:djvu},
title = {{Feature Extraction, Construction and Selection}},
year = {1998}
}
@book{AutoridadNacionaldelServicioCivil2021,
abstract = {Seiring dengan kemajuan ilmu pengetahuan dan teknologi yang menjadi pusat perhatian dunia. Maka manusia dituntut untuk menciptakan peralatan-peralatan canggih untuk teknologi muktahir. Baik itu dalam bidang bisnis, perdagangan, kesehatan, militer, pendidikan, komunikasi dan budaya maupun bidang-bidang lainnya. Maka teknologi ini membawa perubahan pada peralatan-peralatan yang dulunya bekerja secara analog mulai dikembangkan secara digital, dan bahkan yang bekerjanya secara manual sekarang banyak dikembangkan secara otomatis, seperti kamera digital, handycam, dan sebagainya, dalam pembacaan pengukuran juga sudah dikembangkan ke dalam teknik digital. Contohnya perangkat Load Cell. Dan keuntungan menggunakan Load Cell adalah untuk mempermudah dalam pembacaan data untuk meminimalkan kesalahan dalam pembacaan data yang disebabkan adanya human error.Pada pemilihan Load Cell bertujuan untuk memilih kecocokan dalam membuat rancang bangun alat uji tarik kapasitas 3 ton, dimana dalam pemilihan ini kami memilih jenis load cell “S” karna alat yang kita rancang adalah uji tarik bukan uji tekan. Dengan kapasitas load cell 5 ton. Untuk membuat jarak aman dalam pengujian specimen ST41. Load Cell menggunakan system perangkat elektronik pengolahan data yang menjadi sebuah kurva tegangan regangan. Data-data yang diperoleh tersebut berupa besarnya pembebanan hasil dari pengujian specimen ST41. Kata},
author = {{Autoridad Nacional del Servicio Civil}},
booktitle = {Angewandte Chemie International Edition, 6(11), 951–952.},
file = {:home/lk/Documents/Books/MachineLearning/FeatureSelection/Feature engineering made easy.pdf:pdf},
isbn = {9781787287600},
pages = {2013--2015},
title = {{済無No Title No Title No Title}},
year = {2021}
}
@book{Kuhn2019,
abstract = {The process of developing predictive models includes many stages. Most resources focus on the modeling algorithms but neglect other critical aspects of the modeling process. This book describes techniques for finding the best representations of predictors for modeling and for nding the best subset of predictors for improving model performance. A variety of example data sets are used to illustrate the techniques along with R programs for reproducing the results.},
author = {Kuhn, Max and Johnson, Kjell},
booktitle = {Feature Engineering and Selection},
doi = {10.1201/9781315108230},
file = {:home/lk/Documents/Books/MachineLearning/FeatureSelection/Feature Engineering and Selection.pdf:pdf},
isbn = {9781138079229},
title = {{Feature Engineering and Selection}},
year = {2019}
}
@article{Cleaning,
author = {Cleaning, Data and Selection, Feature and Brownlee, Jason},
file = {:home/lk/Documents/Books/MachineLearning/FeatureSelection/Data Preparation for Machine Learning.pdf:pdf},
title = {{⁠ M ⁠ a ⁠ c ⁠ h ⁠ i ⁠ n ⁠ e ⁠ ⁠ L ⁠ e ⁠ a ⁠ r ⁠ n ⁠ i ⁠ n ⁠ g and Data Transforms in Python}}
}
@article{Deng2019,
abstract = {Big multimedia data is heterogeneous in essence, that is, the data may be a mixture of video, audio, text, and images. This is due to the prevalence of novel applications in recent years, such as social media, video sharing, and location based services (LBS), etc. In many multimedia applications, for example, video/image tagging and multimedia recommendation, text classification techniques have been used extensively to facilitate multimedia data processing. In this paper, we give a comprehensive review on feature selection techniques for text classification. We begin by introducing some popular representation schemes for documents, and similarity measures used in text classification. Then, we review the most popular text classifiers, including Nearest Neighbor (NN) method, Na{\"{i}}ve Bayes (NB), Support Vector Machine (SVM), Decision Tree (DT), and Neural Networks. Next, we survey four feature selection models, namely the filter, wrapper, embedded and hybrid, discussing pros and cons of the state-of-the-art feature selection approaches. Finally, we conclude the paper and give a brief introduction to some interesting feature selection work that does not belong to the four models.},
author = {Deng, Xuelian and Li, Yuqing and Weng, Jian and Zhang, Jilian},
doi = {10.1007/s11042-018-6083-5},
file = {:home/lk/Documents/Books/MachineLearning/FeatureSelection/Computational methods of feature selection.pdf:pdf},
issn = {15737721},
journal = {Multimedia Tools and Applications},
keywords = {Feature Selection,Multimedia,Text classification,Text classifiers},
number = {3},
pages = {3797--3816},
title = {{Feature selection for text classification: A review}},
volume = {78},
year = {2019}
}
@book{Kuhn2013,
abstract = {Applied Predictive Modeling covers the overall predictive modeling process, beginning with the crucial steps of data preprocessing, data splitting and foundations of model tuning. The text then provides intuitive explanations of numerous common and modern regression and classification techniques, always with an emphasis on illustrating and solving real data problems. The text illustrates all parts of the modeling process through many hands-on, real-life examples, and every chapter contains extensive R code for each step of the process. This multi-purpose text can be used as an introduction to predictive models and the overall modeling process, a practitioner's reference handbook, or as a text for advanced undergraduate or graduate level predictive modeling courses. To that end, each chapter contains problem sets to help solidify the covered concepts and uses data available in the book's R package. This text is intended for a broad audience as both an introduction to predictive models as well as a guide to applying them. Non-mathematical readers will appreciate the intuitive explanations of the techniques while an emphasis on problem-solving with real data across a wide variety of applications will aid practitioners who wish to extend their expertise. Readers should have knowledge of basic statistical ideas, such as correlation and linear regression analysis. While the text is biased against complex equations, a mathematical background is needed for advanced topics.},
author = {Kuhn, Max and Johnson, Kjell},
booktitle = {Applied Predictive Modeling},
doi = {10.1007/978-1-4614-6849-3},
file = {:home/lk/Documents/Books/MachineLearning/FeatureSelection/Applied Predictive Modeling.pdf:pdf},
isbn = {9781461468493},
pages = {1--600},
title = {{Applied predictive modeling}},
year = {2013}
}
@book{Stanczyk2018,
author = {Sta{\'{n}}czyk, Urszula},
file = {:home/lk/Documents/Books/MachineLearning/FeatureSelection/Advances in Feature Selection for Data and Pattern Recognition.pdf:pdf},
isbn = {9783319675879},
title = {{Advance in feature Selection for Data and Pattern}},
year = {2018}
}
@misc{Dunne2006,
abstract = {An accessible and up-to-date treatment featuring the connection between neural networks and statistics. A Statistical Approach to Neural Networks for Pattern Recognition presents a statistical treatment of the Multilayer Perceptron (MLP), which is the most widely used of the neural network models. This book aims to answer questions that arise when statisticians are first confronted with this type of model, such as: How robust is the model to outliers? Could the model be made more robust? Which points will have a high leverage? What are good starting values for the fitting algorithm? Thorough answers to these questions and many more are included, as well as worked examples and selected problems for the reader. Discussions on the use of MLP models with spatial and spectral data are also included. Further treatment of highly important principal aspects of the MLP are provided, such as the robustness of the model in the event of outlying or atypical data; the influence and sensitivity curves of the MLP; why the MLP is a fairly robust model; and modifications to make the MLP more robust. The author also provides clarification of several misconceptions that are prevalent in existing neural network literature. Throughout the book, the MLP model is extended in several directions to show that a statistical modeling approach can make valuable contributions, and further exploration for fitting MLP models is made possible via the R and S-PLUS{\textregistered} codes that are available on the book's related Web site. A Statistical Approach to Neural Networks for Pattern Recognition successfully connects logistic regression and linear discriminant analysis, thus making it a critical reference and self-study guide for students and professionals alike in the fields of mathematics, statistics, computer science, and electrical engineering. {\textcopyright} 2007 John Wiley & Sons, Inc. All rights reserved.},
author = {Dunne, Robert A.},
booktitle = {A Statistical Approach to Neural Networks for Pattern Recognition},
doi = {10.1002/9780470148150},
file = {:home/lk/Documents/Books/MachineLearning/FeatureSelection/A statistical approach to neural networks for pattern recognition.djvu:djvu},
isbn = {9780471741084},
pages = {1--268},
title = {{A Statistical Approach to Neural Networks for Pattern Recognition}},
year = {2006}
}
